{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of \"Lightweight Probabilistic Deep Networks\"\n",
    "#  https://arxiv.org/pdf/1805.11327.pdf\n",
    "\n",
    "# Create data based on some simple function\n",
    "# Create a model (keras) that can be trained\n",
    "# Run predictions\n",
    "# Add different levels noise to the input features\n",
    "#  - Remember the level of uncertainty for each example and feature\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datagen(x):\n",
    "    return 0.05 * np.power(x, 3.0) + 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.997666705899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f54d41d0da0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f54d4277cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(666)\n",
    "\n",
    "nrofExamples = 100000\n",
    "input_var = 1.0\n",
    "e = np.random.randn(nrofExamples, 1) * np.sqrt(input_var)\n",
    "X = np.random.uniform(low=-5.0, high=5.0, size=(nrofExamples,1))\n",
    "y = datagen(X) + e\n",
    "xv = np.ones((nrofExamples, 1)) * input_var\n",
    "print(np.std(e)**2)\n",
    "\n",
    "plt.scatter(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(mu_in, var_in):\n",
    "    dist = tf.distributions.Normal(loc=0.0, scale=1.0)\n",
    "    sigma = tf.sqrt(var_in)\n",
    "    pdf = dist.prob(mu_in / tf.sqrt(var_in))\n",
    "    cdf = dist.cdf(mu_in / tf.sqrt(var_in))\n",
    "    \n",
    "    mu_relu = mu_in * cdf + sigma * pdf\n",
    "    var_relu = (mu_in + var_in) * cdf + mu_in*sigma*pdf + tf.pow(mu_relu, 2)\n",
    "    \n",
    "    return mu_relu, var_relu\n",
    "\n",
    "def prob_dense(sz, mu_in, var_in, use_relu=False):\n",
    "    d = int(mu_in.get_shape()[1])\n",
    "    W = tf.Variable(tf.random_normal((d, sz)), dtype=tf.float32)\n",
    "    b = tf.Variable(tf.random_normal((sz,)), dtype=tf.float32)\n",
    "    mu_dense = tf.nn.relu(tf.matmul(mu_in, W) + b)\n",
    "    sq = tf.transpose(W**2)\n",
    "    var_dense = var_in @ tf.matrix_transpose(sq)\n",
    "    #print((var_in.shape.as_list(), sq.shape.as_list(), var_out.shape.as_list()))\n",
    "    if use_relu:\n",
    "        mu_relu, var_relu = relu(mu_dense, var_dense)\n",
    "    else:\n",
    "        mu_relu, var_relu = (mu_dense, var_dense)\n",
    "    return mu_relu, var_relu\n",
    "\n",
    "def probnet(mu_in, var_in):\n",
    "    mu1, var1 = prob_dense(20, mu_in, var_in, use_relu=True)\n",
    "    mu2, var2 = prob_dense(20, mu1, var1, use_relu=True)\n",
    "    mu3, var3 = prob_dense(20, mu2, var2, use_relu=True)\n",
    "    mu4, var4 = prob_dense(20, mu3, var3, use_relu=True)\n",
    "    mu_out, var_out = prob_dense(1, mu4, var4)\n",
    "    return mu_out, var_out\n",
    "\n",
    "def prob_loss(y_mu, y_var, y_true):\n",
    "    loss = tf.reduce_sum((y_true-y_mu)**2 / y_var + tf.log(y_var))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    1  Step:  100  Avg loss: 428.119  varEst: 6.451  varMean: 970109.625\n",
      "Epoch:    1  Step:  200  Avg loss: 406.646  varEst: 6.703  varMean: 496334.531\n",
      "Epoch:    1  Step:  300  Avg loss: 385.340  varEst: 6.497  varMean: 257379.062\n",
      "Epoch:    1  Step:  400  Avg loss: 364.296  varEst: 6.512  varMean: 129300.102\n",
      "Epoch:    1  Step:  500  Avg loss: 342.170  varEst: 6.572  varMean: 64199.078\n",
      "Epoch:    1  Step:  600  Avg loss: 322.270  varEst: 6.595  varMean: 34552.250\n",
      "Epoch:    1  Step:  700  Avg loss: 301.401  varEst: 6.451  varMean: 17979.689\n",
      "Epoch:    1  Step:  800  Avg loss: 279.744  varEst: 6.488  varMean: 9245.878\n",
      "Epoch:    1  Step:  900  Avg loss: 256.420  varEst: 6.642  varMean: 4574.238\n",
      "Epoch:    1  Step: 1000  Avg loss: 232.094  varEst: 6.615  varMean: 2152.675\n",
      "Epoch:    1  Step: 1100  Avg loss: 206.070  varEst: 6.114  varMean: 973.603\n",
      "Epoch:    1  Step: 1200  Avg loss: 179.567  varEst: 6.250  varMean: 434.551\n",
      "Epoch:    1  Step: 1300  Avg loss: 152.152  varEst: 6.425  varMean: 179.153\n",
      "Epoch:    1  Step: 1400  Avg loss: 125.701  varEst: 6.601  varMean: 71.844\n",
      "Epoch:    1  Step: 1500  Avg loss: 104.164  varEst: 6.330  varMean: 28.928\n",
      "Epoch:    1  Step: 1600  Avg loss: 89.031  varEst: 6.335  varMean: 13.544\n",
      "Epoch:    1  Step: 1700  Avg loss: 79.630  varEst: 6.627  varMean: 7.800\n",
      "Epoch:    1  Step: 1800  Avg loss: 74.313  varEst: 6.593  varMean: 6.246\n",
      "Epoch:    1  Step: 1900  Avg loss: 72.799  varEst: 6.469  varMean: 5.957\n",
      "Epoch:    1  Step: 2000  Avg loss: 72.260  varEst: 6.607  varMean: 6.113\n",
      "Epoch:    1  Step: 2100  Avg loss: 73.429  varEst: 7.016  varMean: 6.316\n",
      "Epoch:    1  Step: 2200  Avg loss: 70.895  varEst: 6.530  varMean: 6.173\n",
      "Epoch:    1  Step: 2300  Avg loss: 69.762  varEst: 6.312  varMean: 6.152\n",
      "Epoch:    1  Step: 2400  Avg loss: 69.872  varEst: 6.425  varMean: 6.202\n",
      "Epoch:    1  Step: 2500  Avg loss: 70.135  varEst: 6.473  varMean: 6.196\n",
      "Epoch:    1  Step: 2600  Avg loss: 69.576  varEst: 6.394  varMean: 6.156\n",
      "Epoch:    1  Step: 2700  Avg loss: 70.220  varEst: 6.502  varMean: 6.248\n",
      "Epoch:    1  Step: 2800  Avg loss: 70.375  varEst: 6.628  varMean: 6.408\n",
      "Epoch:    1  Step: 2900  Avg loss: 68.714  varEst: 6.547  varMean: 6.232\n",
      "Epoch:    1  Step: 3000  Avg loss: 72.240  varEst: 7.152  varMean: 6.926\n",
      "Epoch:    1  Step: 3100  Avg loss: 69.147  varEst: 6.441  varMean: 6.282\n",
      "Epoch:    1  Step: 3125  Avg loss: 65.866  varEst: 5.858  varMean: 5.832\n",
      "Epoch:    2  Step:  100  Avg loss: 68.930  varEst: 6.451  varMean: 6.233\n",
      "Epoch:    2  Step:  200  Avg loss: 70.087  varEst: 6.703  varMean: 6.573\n",
      "Epoch:    2  Step:  300  Avg loss: 68.996  varEst: 6.497  varMean: 6.280\n",
      "Epoch:    2  Step:  400  Avg loss: 68.921  varEst: 6.512  varMean: 6.314\n",
      "Epoch:    2  Step:  500  Avg loss: 68.692  varEst: 6.572  varMean: 6.483\n",
      "Epoch:    2  Step:  600  Avg loss: 68.919  varEst: 6.595  varMean: 6.520\n",
      "Epoch:    2  Step:  700  Avg loss: 69.270  varEst: 6.451  varMean: 6.431\n",
      "Epoch:    2  Step:  800  Avg loss: 69.180  varEst: 6.488  varMean: 6.470\n",
      "Epoch:    2  Step:  900  Avg loss: 68.875  varEst: 6.642  varMean: 6.555\n",
      "Epoch:    2  Step: 1000  Avg loss: 69.851  varEst: 6.615  varMean: 6.647\n",
      "Epoch:    2  Step: 1100  Avg loss: 68.593  varEst: 6.114  varMean: 6.182\n",
      "Epoch:    2  Step: 1200  Avg loss: 68.202  varEst: 6.250  varMean: 6.124\n",
      "Epoch:    2  Step: 1300  Avg loss: 68.560  varEst: 6.425  varMean: 6.419\n",
      "Epoch:    2  Step: 1400  Avg loss: 69.394  varEst: 6.601  varMean: 6.511\n",
      "Epoch:    2  Step: 1500  Avg loss: 68.557  varEst: 6.330  varMean: 6.266\n",
      "Epoch:    2  Step: 1600  Avg loss: 68.102  varEst: 6.335  varMean: 6.141\n",
      "Epoch:    2  Step: 1700  Avg loss: 70.502  varEst: 6.627  varMean: 6.669\n",
      "Epoch:    2  Step: 1800  Avg loss: 68.964  varEst: 6.593  varMean: 6.532\n",
      "Epoch:    2  Step: 1900  Avg loss: 69.697  varEst: 6.469  varMean: 6.513\n",
      "Epoch:    2  Step: 2000  Avg loss: 69.774  varEst: 6.607  varMean: 6.787\n",
      "Epoch:    2  Step: 2100  Avg loss: 70.858  varEst: 7.016  varMean: 6.889\n",
      "Epoch:    2  Step: 2200  Avg loss: 68.891  varEst: 6.530  varMean: 6.399\n",
      "Epoch:    2  Step: 2300  Avg loss: 68.358  varEst: 6.312  varMean: 6.402\n",
      "Epoch:    2  Step: 2400  Avg loss: 68.764  varEst: 6.425  varMean: 6.501\n",
      "Epoch:    2  Step: 2500  Avg loss: 69.491  varEst: 6.473  varMean: 6.491\n",
      "Epoch:    2  Step: 2600  Avg loss: 68.872  varEst: 6.394  varMean: 6.529\n",
      "Epoch:    2  Step: 2700  Avg loss: 69.671  varEst: 6.502  varMean: 6.534\n",
      "Epoch:    2  Step: 2800  Avg loss: 70.060  varEst: 6.628  varMean: 6.719\n",
      "Epoch:    2  Step: 2900  Avg loss: 68.318  varEst: 6.547  varMean: 6.520\n",
      "Epoch:    2  Step: 3000  Avg loss: 71.914  varEst: 7.152  varMean: 7.225\n",
      "Epoch:    2  Step: 3100  Avg loss: 68.780  varEst: 6.441  varMean: 6.610\n",
      "Epoch:    2  Step: 3125  Avg loss: 65.499  varEst: 5.858  varMean: 6.074\n",
      "Epoch:    3  Step:  100  Avg loss: 68.761  varEst: 6.451  varMean: 6.539\n",
      "Epoch:    3  Step:  200  Avg loss: 69.898  varEst: 6.703  varMean: 6.886\n",
      "Epoch:    3  Step:  300  Avg loss: 68.802  varEst: 6.497  varMean: 6.444\n",
      "Epoch:    3  Step:  400  Avg loss: 68.726  varEst: 6.512  varMean: 6.512\n",
      "Epoch:    3  Step:  500  Avg loss: 68.474  varEst: 6.572  varMean: 6.683\n",
      "Epoch:    3  Step:  600  Avg loss: 68.832  varEst: 6.595  varMean: 6.795\n",
      "Epoch:    3  Step:  700  Avg loss: 69.100  varEst: 6.451  varMean: 6.560\n",
      "Epoch:    3  Step:  800  Avg loss: 69.075  varEst: 6.488  varMean: 6.654\n",
      "Epoch:    3  Step:  900  Avg loss: 68.752  varEst: 6.642  varMean: 6.688\n",
      "Epoch:    3  Step: 1000  Avg loss: 69.760  varEst: 6.615  varMean: 6.891\n",
      "Epoch:    3  Step: 1100  Avg loss: 68.444  varEst: 6.114  varMean: 6.246\n",
      "Epoch:    3  Step: 1200  Avg loss: 68.046  varEst: 6.250  varMean: 6.270\n",
      "Epoch:    3  Step: 1300  Avg loss: 68.478  varEst: 6.425  varMean: 6.570\n",
      "Epoch:    3  Step: 1400  Avg loss: 69.319  varEst: 6.601  varMean: 6.680\n",
      "Epoch:    3  Step: 1500  Avg loss: 68.474  varEst: 6.330  varMean: 6.409\n",
      "Epoch:    3  Step: 1600  Avg loss: 67.954  varEst: 6.335  varMean: 6.268\n",
      "Epoch:    3  Step: 1700  Avg loss: 70.422  varEst: 6.627  varMean: 6.841\n",
      "Epoch:    3  Step: 1800  Avg loss: 68.900  varEst: 6.593  varMean: 6.638\n",
      "Epoch:    3  Step: 1900  Avg loss: 69.622  varEst: 6.469  varMean: 6.652\n",
      "Epoch:    3  Step: 2000  Avg loss: 69.793  varEst: 6.607  varMean: 6.943\n",
      "Epoch:    3  Step: 2100  Avg loss: 70.772  varEst: 7.016  varMean: 6.957\n",
      "Epoch:    3  Step: 2200  Avg loss: 68.837  varEst: 6.530  varMean: 6.562\n",
      "Epoch:    3  Step: 2300  Avg loss: 68.313  varEst: 6.312  varMean: 6.484\n",
      "Epoch:    3  Step: 2400  Avg loss: 68.735  varEst: 6.425  varMean: 6.598\n",
      "Epoch:    3  Step: 2500  Avg loss: 69.454  varEst: 6.473  varMean: 6.596\n",
      "Epoch:    3  Step: 2600  Avg loss: 68.797  varEst: 6.394  varMean: 6.585\n",
      "Epoch:    3  Step: 2700  Avg loss: 69.645  varEst: 6.502  varMean: 6.600\n",
      "Epoch:    3  Step: 2800  Avg loss: 70.045  varEst: 6.628  varMean: 6.774\n",
      "Epoch:    3  Step: 2900  Avg loss: 68.278  varEst: 6.547  varMean: 6.603\n",
      "Epoch:    3  Step: 3000  Avg loss: 71.871  varEst: 7.152  varMean: 7.312\n",
      "Epoch:    3  Step: 3100  Avg loss: 68.718  varEst: 6.441  varMean: 6.642\n",
      "Epoch:    3  Step: 3125  Avg loss: 65.428  varEst: 5.858  varMean: 6.146\n",
      "Epoch:    4  Step:  100  Avg loss: 68.740  varEst: 6.451  varMean: 6.614\n",
      "Epoch:    4  Step:  200  Avg loss: 69.867  varEst: 6.703  varMean: 6.971\n",
      "Epoch:    4  Step:  300  Avg loss: 68.769  varEst: 6.497  varMean: 6.526\n",
      "Epoch:    4  Step:  400  Avg loss: 68.712  varEst: 6.512  varMean: 6.596\n",
      "Epoch:    4  Step:  500  Avg loss: 68.441  varEst: 6.572  varMean: 6.722\n",
      "Epoch:    4  Step:  600  Avg loss: 68.834  varEst: 6.595  varMean: 6.843\n",
      "Epoch:    4  Step:  700  Avg loss: 69.066  varEst: 6.451  varMean: 6.621\n",
      "Epoch:    4  Step:  800  Avg loss: 69.067  varEst: 6.488  varMean: 6.719\n",
      "Epoch:    4  Step:  900  Avg loss: 68.716  varEst: 6.642  varMean: 6.764\n",
      "Epoch:    4  Step: 1000  Avg loss: 69.753  varEst: 6.615  varMean: 6.917\n",
      "Epoch:    4  Step: 1100  Avg loss: 68.403  varEst: 6.114  varMean: 6.271\n",
      "Epoch:    4  Step: 1200  Avg loss: 68.012  varEst: 6.250  varMean: 6.301\n",
      "Epoch:    4  Step: 1300  Avg loss: 68.455  varEst: 6.425  varMean: 6.588\n",
      "Epoch:    4  Step: 1400  Avg loss: 69.297  varEst: 6.601  varMean: 6.705\n",
      "Epoch:    4  Step: 1500  Avg loss: 68.462  varEst: 6.330  varMean: 6.436\n",
      "Epoch:    4  Step: 1600  Avg loss: 67.924  varEst: 6.335  varMean: 6.310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    4  Step: 1700  Avg loss: 70.407  varEst: 6.627  varMean: 6.890\n",
      "Epoch:    4  Step: 1800  Avg loss: 68.881  varEst: 6.593  varMean: 6.661\n",
      "Epoch:    4  Step: 1900  Avg loss: 69.624  varEst: 6.469  varMean: 6.690\n",
      "Epoch:    4  Step: 2000  Avg loss: 69.789  varEst: 6.607  varMean: 6.967\n",
      "Epoch:    4  Step: 2100  Avg loss: 70.749  varEst: 7.016  varMean: 6.994\n",
      "Epoch:    4  Step: 2200  Avg loss: 68.807  varEst: 6.530  varMean: 6.619\n",
      "Epoch:    4  Step: 2300  Avg loss: 68.298  varEst: 6.312  varMean: 6.523\n",
      "Epoch:    4  Step: 2400  Avg loss: 68.727  varEst: 6.425  varMean: 6.634\n",
      "Epoch:    4  Step: 2500  Avg loss: 69.446  varEst: 6.473  varMean: 6.609\n",
      "Epoch:    4  Step: 2600  Avg loss: 68.763  varEst: 6.394  varMean: 6.604\n",
      "Epoch:    4  Step: 2700  Avg loss: 69.638  varEst: 6.502  varMean: 6.610\n",
      "Epoch:    4  Step: 2800  Avg loss: 70.039  varEst: 6.628  varMean: 6.806\n",
      "Epoch:    4  Step: 2900  Avg loss: 68.260  varEst: 6.547  varMean: 6.617\n",
      "Epoch:    4  Step: 3000  Avg loss: 71.850  varEst: 7.152  varMean: 7.346\n",
      "Epoch:    4  Step: 3100  Avg loss: 68.696  varEst: 6.441  varMean: 6.631\n",
      "Epoch:    4  Step: 3125  Avg loss: 65.414  varEst: 5.858  varMean: 6.138\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "learning_rate = 0.0005\n",
    "nrof_epochs = 4\n",
    "show_every = 100\n",
    "    \n",
    "sess = tf.Session()\n",
    "\n",
    "# Create a dataset tensor from the images and the labels\n",
    "nrof_batches_per_epoch = int(np.ceil(X.shape[0] / batch_size))\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X.astype(np.float32), xv.astype(np.float32), y.astype(np.float32)))\n",
    "\n",
    "# Automatically refill the data queue when empty\n",
    "dataset = dataset.repeat()\n",
    "# Create batches of data\n",
    "dataset = dataset.batch(batch_size)\n",
    "# Prefetch data for faster consumption\n",
    "#dataset = dataset.prefetch(batch_size)\n",
    "\n",
    "# Create an iterator over the dataset\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "# Initialize the iterator\n",
    "sess.run(iterator.initializer)\n",
    "\n",
    "# Neural Net Input (images, labels)\n",
    "x_mu_batch, x_var_batch, y_true_batch = iterator.get_next()\n",
    "\n",
    "y_mu, y_var = probnet(x_mu_batch, x_var_batch)\n",
    "\n",
    "loss = prob_loss(y_mu, y_var, y_true_batch)\n",
    "#print(loss)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss)\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Training cycle\n",
    "for epoch in range(1, nrof_epochs+1):\n",
    "    loss_list = []\n",
    "    y_mu_list = []\n",
    "    y_var_list = []\n",
    "    y_true_list = []\n",
    "    for step in range(1, nrof_batches_per_epoch+1):\n",
    "        _, loss_, y_mu_, y_var_, y_true_  = sess.run([train_op, loss, y_mu, y_var, y_true_batch])\n",
    "        loss_list.append(loss_)\n",
    "        y_mu_list.append(y_mu_)\n",
    "        y_var_list.append(y_var_)\n",
    "        y_true_list.append(y_true_)\n",
    "        \n",
    "        if step % show_every==0 or step==nrof_batches_per_epoch:\n",
    "            y_mu_arr = np.concatenate(y_mu_list)\n",
    "            y_var_arr = np.concatenate(y_var_list)\n",
    "            y_true_arr = np.concatenate(y_true_list)\n",
    "            var_est = np.std(y_mu_arr-y_true_arr)**2\n",
    "            var_mean = np.mean(y_var_arr)\n",
    "            print('Epoch: %4d  Step: %4d  Avg loss: %.3f  varEst: %.3f  varMean: %.3f' % (epoch, step, np.mean(loss_list), var_est, var_mean))\n",
    "            loss_list = []\n",
    "            y_mu_list = []\n",
    "            y_var_list = []\n",
    "            y_true_list = []\n",
    "\n",
    "print('Done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_test = np.arange(-7.0, 7.0, 0.01)\n",
    "var_test = np.ones_like(mu_test) * \n",
    "y_test = datagen(x_test)\n",
    "\n",
    "val_set = tf.data.Dataset.from_tensor_slices((x_test.astype(np.float32), xv.astype(np.float32), y_test.astype(np.float32)))\n",
    "\n",
    "# Automatically refill the data queue when empty\n",
    "dataset = dataset.repeat()\n",
    "# Create batches of data\n",
    "dataset = dataset.batch(batch_size)\n",
    "# Prefetch data for faster consumption\n",
    "#dataset = dataset.prefetch(batch_size)\n",
    "\n",
    "# Create an iterator over the dataset\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "# Initialize the iterator\n",
    "sess.run(iterator.initializer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.arange(-7.0, 7.0, 0.01)\n",
    "y_test_hat = model.predict([x_test)\n",
    "\n",
    "y_test = datagen(x_test)\n",
    "plt.scatter(x_test, y_test_hat, s=3)\n",
    "plt.plot(x_test, y_test, 'r-')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
